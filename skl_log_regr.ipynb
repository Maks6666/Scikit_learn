{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of importing moduls, let's create our own data, where there will be a column with\n",
    "# features that are suitable for binary classification, since logistic\n",
    "# regression is the most advantageous method for solving binary and multi-classification problems\n",
    "# while linear regression is better at predicting numerical values ​​over a broader\n",
    "# spectrum\n",
    "\n",
    "\n",
    "# array with values ​​from 0 to 9 (10 values)\n",
    "\n",
    "\n",
    "# reshape(-1, 1) reshapes the array so that it contains one column (1) and a number of rows equal to the number of elements in the original array.\n",
    "# This allows you to convert a one-dimensional array to a multi-dimensional array column.\n",
    "x = np.arange(10).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the array of labels with zeros and ones in random order\n",
    "# manually\n",
    "# y = np.array([1,1,0,0,0,1,1,0,0,1,0,1,0,0,1,1,1,0,0,1])\n",
    "\n",
    "# or automatically\n",
    "# y = np.random.randint(2, size=10)\n",
    "\n",
    "# since in our case the data volume is small, which may negatively affect the accuracy of the model\n",
    "# you can enter data according to some simple and understandable principle, for example, all even numbers in the x array will correspond\n",
    "# 0 in the array y, respectively, odd ones will correspond to 1\n",
    "\n",
    "y = np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n",
    "\n",
    "# массивы x и у соответсвуют друг другу "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver=\"liblinear\", C=10.0, random_state=0)\n",
    "\n",
    "# solver=\"liblinear\"\n",
    "# This parameter specifies the optimization algorithm used to solve the optimization problem,\n",
    "# which occurs when training logistic regression.\n",
    "# liblinear is a method that works well for small data sets.\n",
    "#!!!! - There are other options such as lbfgs, newton-cg, sag, and saga.\n",
    "\n",
    "\n",
    "#C=10.0\n",
    "# Regularization parameter (denoted as C).\n",
    "# Regularization is used to prevent model overfitting.\n",
    "# The value of C is the inverse of the regularization strength.\n",
    "# Large values ​​of C correspond to weak regularization,\n",
    "# while small values ​​of C correspond to strong regularization.\n",
    "# A value of 10.0 indicates relatively weak regularization.\n",
    "\n",
    "# random_state=0:\n",
    "# This parameter sets the initial value for the random number generator. This affects the random order,\n",
    "# where the data is broken down or model weights are initialized.\n",
    "# Setting random_state to a specific number allows the results to be reproduced when running the code again.\n",
    "# In this case, setting random_state=0 means\n",
    "# that the random number generator will start from an initial state of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10.0, random_state=0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10.0, random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10.0, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 1 1 1]\n",
      "[0 1 0 1 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x)\n",
    "print(pred)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.61852578 0.38147422]\n",
      " [0.59181906 0.40818094]\n",
      " [0.56455889 0.43544111]\n",
      " [0.53690276 0.46309724]\n",
      " [0.5090177  0.4909823 ]\n",
      " [0.48107642 0.51892358]\n",
      " [0.45325299 0.54674701]\n",
      " [0.4257186  0.5742814 ]\n",
      " [0.39863732 0.60136268]\n",
      " [0.37216236 0.62783764]]\n"
     ]
    }
   ],
   "source": [
    "# this code will actually print the probability of each object in array x belonging to the corresponding class in array y\n",
    "# that is, if we consider the first object of the array \"x\" - 0, then its membership in class 0 from the array \"y\" will be equal\n",
    "# 0.61852578%, and to class 1 - 0.38147422%, which is the correct result since object 0 from array \"x\" is indeed\n",
    "# belongs to class 0 of array \"y\"\n",
    "\n",
    "# the accuracy of the prediction depends on the accuracy of the model\n",
    "\n",
    "# in this case we have only two classes in the \"y\" array - 0 and 1\n",
    "# and 10 objects in the \"x\" array\n",
    "\n",
    "\n",
    "prob_pred = model.predict_proba(x)\n",
    "print(prob_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix - provides information on how many samples were classified correctly or incorrectly\n",
    "# for each class.\n",
    "conf = confusion_matrix(y, pred)\n",
    "print(conf)\n",
    "\n",
    "# if the output of the error matrix is ​​like this -\n",
    "\n",
    "# [[3 2]\n",
    "#  [1 4]]\n",
    "\n",
    "# That:\n",
    "\n",
    "#3 - samples were correctly classified as True Negative.\n",
    "#4 - samples were correctly classified as True Positive.\n",
    "#2 - the sample was incorrectly classified as positive (False Positive).\n",
    "#1 - the sample was incorrectly classified as False Negative.\n",
    "\n",
    "# if the matrix output is different, just add the resulting values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines are needed to calculate several metrics for assessing the quality of classification\n",
    "# and provides summary information in a convenient way. Metrics include precision,\n",
    "# completeness (recall), F1-score (F1-score) and support (support) for each class.\n",
    "\n",
    "report = classification_report(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.60      0.60      0.60         5\\n           1       0.60      0.60      0.60         5\\n\\n    accuracy                           0.60        10\\n   macro avg       0.60      0.60      0.60        10\\nweighted avg       0.60      0.60      0.60        10\\n'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report\n",
    "\n",
    "# precision: Precision is the proportion of correctly classified positive samples relative to all samples,\n",
    "# predicted as positive. For class 0, the accuracy is 0.60, for class 1 - 0.75.\n",
    "\n",
    "# recall: Recall is the proportion of correctly classified positive samples relative to all actually positive samples.\n",
    "# For class 0 the completeness is 0.60, for class 1 it is 0.75.\n",
    "\n",
    "# f1-score: F1-score is the harmonic mean between precision and recall.\n",
    "# It's a balance between precision and completeness. For class 0, the F1-measure is 0.60, for class 1 - 0.75.\n",
    "\n",
    "# support: Number of actual samples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60         5\n",
      "           1       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.60        10\n",
      "   macro avg       0.60      0.60      0.60        10\n",
      "weighted avg       0.60      0.60      0.60        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
